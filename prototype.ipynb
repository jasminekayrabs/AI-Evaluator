{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import pickle\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DistilBART model\n",
    "tokenizer_bart = AutoTokenizer.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
    "model_bart = AutoModelForSeq2SeqLM.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T5 tokenizer and model\n",
    "tokenizer_t5 = T5Tokenizer.from_pretrained('t5-small')\n",
    "model_t5 = T5ForConditionalGeneration.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading CNN/DM datasets\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "\n",
    "# Subset of the first 100 articles from the test split\n",
    "subset_of_dataset = []\n",
    "for i in range(100):  # Range can be adjusted based on the number of articles wanted\n",
    "    subset_of_dataset.append(dataset[\"test\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing article from the dataset\n",
    "article_text = dataset[\"test\"][0][\"article\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate summaries using DistilBART\n",
    "def generate_summary_bart(article_text):\n",
    "    # Tokenize the input text and convert to tensor\n",
    "    inputs = tokenizer_bart([article_text], return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    # Generate summary IDs using the model\n",
    "    summary_ids = model_bart.generate(inputs[\"input_ids\"], \n",
    "                                    max_length=150, \n",
    "                                    min_length=40, \n",
    "                                    length_penalty=2.0, \n",
    "                                    num_beams=4, \n",
    "                                    early_stopping=True)\n",
    "    # Decode the generated IDs to text\n",
    "    return tokenizer_bart.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate summaries using T5\n",
    "def generate_summary_t5(article_text):\n",
    "    # Tokenize the input text and convert to tensor\n",
    "    inputs = tokenizer_t5(\"summarize: \" + article_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    # Generate summary IDs using the model\n",
    "    summary_ids = model_t5.generate(inputs[\"input_ids\"], \n",
    "                                    max_length=150, \n",
    "                                    min_length=40, \n",
    "                                    length_penalty=2.0, \n",
    "                                    num_beams=4, \n",
    "                                    early_stopping=True)\n",
    "    # Decode the generated IDs to text\n",
    "    return tokenizer_t5.decode(summary_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate summaries\n",
    "num_articles = 100  # Number of articles to summarize\n",
    "distilbart_summaries = []\n",
    "t5_summaries = []\n",
    "reference_summaries = [] #IInitialize list to store reference summaries\n",
    "\n",
    "for i in range(num_articles):\n",
    "    article_data = dataset[\"test\"][i]\n",
    "    article = article_data[\"article\"]\n",
    "    reference_summary = article_data[\"highlights\"]\n",
    "    \n",
    "    summary_bart = generate_summary_bart(article)\n",
    "    distilbart_summaries.append(summary_bart)\n",
    "    \n",
    "    summary_t5 = generate_summary_t5(article)\n",
    "    t5_summaries.append(summary_t5)\n",
    "\n",
    "    reference_summaries.append(reference_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the summaries\n",
    "import json\n",
    "with open('distilbart_summaries.json', 'w') as f:\n",
    "    json.dump(distilbart_summaries, f)\n",
    "\n",
    "with open('t5_summaries.json', 'w') as f:\n",
    "    json.dump(t5_summaries, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# Function to calculate ROUGE scores for a list of generated summaries against their reference summaries\n",
    "def calculate_rouge_scores(generated_summaries, reference_summaries):\n",
    "    rouge_scores = []\n",
    "    for i in range(len(generated_summaries)):\n",
    "        generated_summary = generated_summaries[i]\n",
    "        reference_summary = reference_summaries[i]\n",
    "        score = scorer.score(reference_summary, generated_summary)\n",
    "        rouge_scores.append(score)\n",
    "    return rouge_scores\n",
    "\n",
    "# Calculate ROUGE scores for DistilBART and T5 summaries\n",
    "rouge_scores_distilbart = calculate_rouge_scores(distilbart_summaries, reference_summaries)\n",
    "rouge_scores_t5 = calculate_rouge_scores(t5_summaries, reference_summaries)\n",
    "\n",
    "# Save ROUGE scores for all summaries\n",
    "rouge_scores_all_distilbart = calculate_rouge_scores(distilbart_summaries, reference_summaries)\n",
    "rouge_scores_all_t5 = calculate_rouge_scores(t5_summaries, reference_summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access ROUGE scores for DistilBART summaries\n",
    "for i, scores in enumerate(rouge_scores_all_distilbart):\n",
    "    print(f\"ROUGE scores for DistilBART summary {i + 1}:\")\n",
    "    print(f\"ROUGE-1 Precision: {scores['rouge1'].precision}\")\n",
    "    print(f\"ROUGE-1 Recall: {scores['rouge1'].recall}\")\n",
    "    print(f\"ROUGE-1 F1 Score: {scores['rouge1'].fmeasure}\")\n",
    "    print(f\"ROUGE-2 Precision: {scores['rouge2'].precision}\")\n",
    "    print(f\"ROUGE-2 Recall: {scores['rouge2'].recall}\")\n",
    "    print(f\"ROUGE-2 F1 Score: {scores['rouge2'].fmeasure}\")\n",
    "    print(f\"ROUGE-L Precision: {scores['rougeL'].precision}\")\n",
    "    print(f\"ROUGE-L Recall: {scores['rougeL'].recall}\")\n",
    "    print(f\"ROUGE-L F1 Score: {scores['rougeL'].fmeasure}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Access ROUGE scores for T5 summaries\n",
    "for i, scores in enumerate(rouge_scores_all_t5):\n",
    "    print(f\"ROUGE scores for T5 summary {i + 1}:\")\n",
    "    print(f\"ROUGE-1 Precision: {scores['rouge1'].precision}\")\n",
    "    print(f\"ROUGE-1 Recall: {scores['rouge1'].recall}\")\n",
    "    print(f\"ROUGE-1 F1 Score: {scores['rouge1'].fmeasure}\")\n",
    "    print(f\"ROUGE-2 Precision: {scores['rouge2'].precision}\")\n",
    "    print(f\"ROUGE-2 Recall: {scores['rouge2'].recall}\")\n",
    "    print(f\"ROUGE-2 F1 Score: {scores['rouge2'].fmeasure}\")\n",
    "    print(f\"ROUGE-L Precision: {scores['rougeL'].precision}\")\n",
    "    print(f\"ROUGE-L Recall: {scores['rougeL'].recall}\")\n",
    "    print(f\"ROUGE-L F1 Score: {scores['rougeL'].fmeasure}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
